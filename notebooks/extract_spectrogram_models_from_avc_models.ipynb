{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/beegfs/jtc440/miniconda3/envs/l3embedding-new/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "from keras.models import Model\n",
    "from l3embedding.audio_model import *\n",
    "from l3embedding.model import load_model\n",
    "from l3embedding import vision_model, audio_model\n",
    "import gzip, bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/scratch/jtc440/sonyc_el3_models\"\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_gzip(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = f.read()\n",
    "        \n",
    "    with gzip.open(filepath + '.gz', 'w') as f:\n",
    "        f.write(data)\n",
    "        \n",
    "def compress_gzip(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = f.read()\n",
    "        \n",
    "    with gzip.open(filepath + '.gz', 'w') as f:\n",
    "        f.write(data)\n",
    "        \n",
    "def compress_bz2(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = f.read()\n",
    "            \n",
    "    with bz2.BZ2File(filepath + '.bz2', 'w') as f:\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dft = 2048\n",
    "n_mels = 128\n",
    "n_hop = 242\n",
    "asr = 48000\n",
    "audio_window_dur = 1\n",
    "\n",
    "# INPUT\n",
    "n_frames = 1 + int((asr * audio_window_dur - n_dft) / float(n_hop))\n",
    "n_frames = 1 + int((asr * audio_window_dur) / float(n_hop))\n",
    "x_a = Input(shape=(n_mels, n_frames, 1), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = '/scratch/jtc440/l3_output/converted_models/embedding/music/cnn_L3_kapredbinputbn/20180905220149/model_best_valid_accuracy.h5'\n",
    "weights_path = '/scratch/jtc440/l3_output/converted_models/embedding/music/cnn_L3_melspec1/20180905154214/model_best_valid_accuracy.h5'\n",
    "weights_path = '/scratch/jtc440/l3_output/converted_models/embedding/music/cnn_L3_melspec2/20180906172059/model_best_valid_accuracy.h5'\n",
    "weights_path = '/scratch/jtc440/l3_output/converted_models/embedding/environmental/cnn_L3_kapredbinputbn/20180905221614/model_best_valid_accuracy.h5'\n",
    "weights_path = '/scratch/jtc440/l3_output/converted_models/embedding/environmental/cnn_L3_melspec1/20180905195208/model_best_valid_accuracy.h5'\n",
    "weights_path = '/scratch/jtc440/l3_output/converted_models/embedding/environmental/cnn_L3_melspec2/20180905191651/model_best_valid_accuracy.h5'\n",
    "weights_path = '/scratch/jtc440/l3_output/converted_models/embedding/music/cnn_L3_melspec2/20190222215808/model_checkpoint.150.h5'\n",
    "weights_path = '/scratch/jtc440/l3_output/converted_models/embedding/music/cnn_L3_melspec1/20190222215922/model_best_valid_accuracy.h5'\n",
    "\n",
    "model_type = weights_path.split('/')[7]\n",
    "\n",
    "if 'kapre' in weights_path:\n",
    "    input_repr = \"linear\"\n",
    "elif 'melspec1' in weights_path:\n",
    "    input_repr = \"mel128\"\n",
    "elif 'melspec2' in weights_path:\n",
    "    input_repr = \"mel256\"\n",
    "\n",
    "subset = weights_path.split('/')[6]\n",
    "if subset[0] == 'e':\n",
    "    subset = 'env'\n",
    "\n",
    "m, inputs, output = load_model(weights_path, model_type, return_io=True)                                     \n",
    "_, x_a = inputs\n",
    "audio_model_output = m.get_layer('audio_model').get_layer('audio_embedding_layer').output\n",
    "\n",
    "audio_embed_model = Model(inputs=x_a, outputs=audio_model_output)\n",
    "\n",
    "audio_output_path = os.path.join(output_dir, 'openl3_audio_{}_{}.h5'.format(input_repr, subset))\n",
    "\n",
    "#audio_embed_model.save_weights(audio_output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, \\\n",
    "    Flatten, Activation, Lambda\n",
    "import tensorflow as tf\n",
    "import keras.regularizers as regularizers\n",
    "\n",
    "\n",
    "def construct_cnn_L3_kapredbinputbn_spec_model():\n",
    "    \"\"\"\n",
    "    Constructs a model that replicates the audio subnetwork  used in Look,\n",
    "    Listen and Learn\n",
    "    Relja Arandjelovic and (2017). Look, Listen and Learn. CoRR, abs/1705.08168, .\n",
    "    Returns\n",
    "    -------\n",
    "    model:  L3 CNN model\n",
    "            (Type: keras.models.Model)\n",
    "    inputs: Model inputs\n",
    "            (Type: list[keras.layers.Input])\n",
    "    outputs: Model outputs\n",
    "            (Type: keras.layers.Layer)\n",
    "    \"\"\"\n",
    "    weight_decay = 1e-5\n",
    "    ####\n",
    "    # Audio subnetwork\n",
    "    ####\n",
    "    n_dft = 512\n",
    "    #n_win = 480\n",
    "    #n_hop = n_win//2\n",
    "    n_hop = 242\n",
    "    asr = 48000\n",
    "    audio_window_dur = 1\n",
    "\n",
    "    n_frames = 1 + int((asr * audio_window_dur) / float(n_hop))\n",
    "    x_a = Input(shape=(int(n_dft / 2) + 1, n_frames, 1), dtype='float32')\n",
    "    y_a = BatchNormalization()(x_a)\n",
    "\n",
    "    # CONV BLOCK 1\n",
    "    n_filter_a_1 = 64\n",
    "    filt_size_a_1 = (3, 3)\n",
    "    pool_size_a_1 = (2, 2)\n",
    "    y_a = Conv2D(n_filter_a_1, filt_size_a_1, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = Conv2D(n_filter_a_1, filt_size_a_1, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = MaxPooling2D(pool_size=pool_size_a_1, strides=2)(y_a)\n",
    "\n",
    "    # CONV BLOCK 2\n",
    "    n_filter_a_2 = 128\n",
    "    filt_size_a_2 = (3, 3)\n",
    "    pool_size_a_2 = (2, 2)\n",
    "    y_a = Conv2D(n_filter_a_2, filt_size_a_2, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = Conv2D(n_filter_a_2, filt_size_a_2, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = MaxPooling2D(pool_size=pool_size_a_2, strides=2)(y_a)\n",
    "\n",
    "    # CONV BLOCK 3\n",
    "    n_filter_a_3 = 256\n",
    "    filt_size_a_3 = (3, 3)\n",
    "    pool_size_a_3 = (2, 2)\n",
    "    y_a = Conv2D(n_filter_a_3, filt_size_a_3, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = Conv2D(n_filter_a_3, filt_size_a_3, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = MaxPooling2D(pool_size=pool_size_a_3, strides=2)(y_a)\n",
    "\n",
    "    # CONV BLOCK 4\n",
    "    n_filter_a_4 = 512\n",
    "    filt_size_a_4 = (3, 3)\n",
    "    pool_size_a_4 = (32, 24)\n",
    "    y_a = Conv2D(n_filter_a_4, filt_size_a_4, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = Conv2D(n_filter_a_4, filt_size_a_4,\n",
    "                 kernel_initializer='he_normal',\n",
    "                 name='audio_embedding_layer', padding='same',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "\n",
    "    m = Model(inputs=x_a, outputs=y_a)\n",
    "    m.name = 'audio_model'\n",
    "\n",
    "    return m, x_a, y_a\n",
    "\n",
    "def construct_cnn_L3_melspec1_spec_model():\n",
    "    \"\"\"\n",
    "    Constructs a model that replicates the audio subnetwork  used in Look,\n",
    "    Listen and Learn\n",
    "    Relja Arandjelovic and (2017). Look, Listen and Learn. CoRR, abs/1705.08168, .\n",
    "    Returns\n",
    "    -------\n",
    "    model:  L3 CNN model\n",
    "            (Type: keras.models.Model)\n",
    "    inputs: Model inputs\n",
    "            (Type: list[keras.layers.Input])\n",
    "    outputs: Model outputs\n",
    "            (Type: keras.layers.Layer)\n",
    "    \"\"\"\n",
    "    weight_decay = 1e-5\n",
    "    ####\n",
    "    # Audio subnetwork\n",
    "    ####\n",
    "    n_dft = 2048\n",
    "    #n_win = 480\n",
    "    #n_hop = n_win//2\n",
    "    n_mels = 128\n",
    "    n_hop = 242\n",
    "    asr = 48000\n",
    "    audio_window_dur = 1\n",
    "\n",
    "    # INPUT\n",
    "    n_frames = 1 + int((asr * audio_window_dur) / float(n_hop))\n",
    "    x_a = Input(shape=(n_mels, n_frames, 1), dtype='float32')\n",
    "    y_a = BatchNormalization()(x_a)\n",
    "\n",
    "    # CONV BLOCK 1\n",
    "    n_filter_a_1 = 64\n",
    "    filt_size_a_1 = (3, 3)\n",
    "    pool_size_a_1 = (2, 2)\n",
    "    y_a = Conv2D(n_filter_a_1, filt_size_a_1, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = Conv2D(n_filter_a_1, filt_size_a_1, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = MaxPooling2D(pool_size=pool_size_a_1, strides=2)(y_a)\n",
    "\n",
    "    # CONV BLOCK 2\n",
    "    n_filter_a_2 = 128\n",
    "    filt_size_a_2 = (3, 3)\n",
    "    pool_size_a_2 = (2, 2)\n",
    "    y_a = Conv2D(n_filter_a_2, filt_size_a_2, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = Conv2D(n_filter_a_2, filt_size_a_2, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = MaxPooling2D(pool_size=pool_size_a_2, strides=2)(y_a)\n",
    "\n",
    "    # CONV BLOCK 3\n",
    "    n_filter_a_3 = 256\n",
    "    filt_size_a_3 = (3, 3)\n",
    "    pool_size_a_3 = (2, 2)\n",
    "    y_a = Conv2D(n_filter_a_3, filt_size_a_3, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = Conv2D(n_filter_a_3, filt_size_a_3, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = MaxPooling2D(pool_size=pool_size_a_3, strides=2)(y_a)\n",
    "\n",
    "    # CONV BLOCK 4\n",
    "    n_filter_a_4 = 512\n",
    "    filt_size_a_4 = (3, 3)\n",
    "    pool_size_a_4 = (16, 24)\n",
    "    y_a = Conv2D(n_filter_a_4, filt_size_a_4, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = Conv2D(n_filter_a_4, filt_size_a_4,\n",
    "                 kernel_initializer='he_normal',\n",
    "                 name='audio_embedding_layer', padding='same',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "\n",
    "    m = Model(inputs=x_a, outputs=y_a)\n",
    "    m.name = 'audio_model'\n",
    "\n",
    "    return m, x_a, y_a\n",
    "\n",
    "\n",
    "def construct_cnn_L3_melspec2_spec_model():\n",
    "    \"\"\"\n",
    "    Constructs a model that replicates the audio subnetwork  used in Look,\n",
    "    Listen and Learn\n",
    "    Relja Arandjelovic and (2017). Look, Listen and Learn. CoRR, abs/1705.08168, .\n",
    "    Returns\n",
    "    -------\n",
    "    model:  L3 CNN model\n",
    "            (Type: keras.models.Model)\n",
    "    inputs: Model inputs\n",
    "            (Type: list[keras.layers.Input])\n",
    "    outputs: Model outputs\n",
    "            (Type: keras.layers.Layer)\n",
    "    \"\"\"\n",
    "    weight_decay = 1e-5\n",
    "    ####\n",
    "    # Audio subnetwork\n",
    "    ####\n",
    "    n_dft = 2048\n",
    "    #n_win = 480\n",
    "    #n_hop = n_win//2\n",
    "    n_mels = 256\n",
    "    n_hop = 242\n",
    "    asr = 48000\n",
    "    audio_window_dur = 1\n",
    "    # INPUT\n",
    "\n",
    "    n_frames = 1 + int((asr * audio_window_dur) / float(n_hop))\n",
    "    x_a = Input(shape=(n_mels, n_frames, 1), dtype='float32')\n",
    "    y_a = BatchNormalization()(x_a)\n",
    "\n",
    "    # CONV BLOCK 1\n",
    "    n_filter_a_1 = 64\n",
    "    filt_size_a_1 = (3, 3)\n",
    "    pool_size_a_1 = (2, 2)\n",
    "    y_a = Conv2D(n_filter_a_1, filt_size_a_1, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = Conv2D(n_filter_a_1, filt_size_a_1, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = MaxPooling2D(pool_size=pool_size_a_1, strides=2)(y_a)\n",
    "\n",
    "    # CONV BLOCK 2\n",
    "    n_filter_a_2 = 128\n",
    "    filt_size_a_2 = (3, 3)\n",
    "    pool_size_a_2 = (2, 2)\n",
    "    y_a = Conv2D(n_filter_a_2, filt_size_a_2, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = Conv2D(n_filter_a_2, filt_size_a_2, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = MaxPooling2D(pool_size=pool_size_a_2, strides=2)(y_a)\n",
    "\n",
    "    # CONV BLOCK 3\n",
    "    n_filter_a_3 = 256\n",
    "    filt_size_a_3 = (3, 3)\n",
    "    pool_size_a_3 = (2, 2)\n",
    "    y_a = Conv2D(n_filter_a_3, filt_size_a_3, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = Conv2D(n_filter_a_3, filt_size_a_3, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = MaxPooling2D(pool_size=pool_size_a_3, strides=2)(y_a)\n",
    "\n",
    "    # CONV BLOCK 4\n",
    "    n_filter_a_4 = 512\n",
    "    filt_size_a_4 = (3, 3)\n",
    "    pool_size_a_4 = (32, 24)\n",
    "    y_a = Conv2D(n_filter_a_4, filt_size_a_4, padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "    y_a = BatchNormalization()(y_a)\n",
    "    y_a = Activation('relu')(y_a)\n",
    "    y_a = Conv2D(n_filter_a_4, filt_size_a_4,\n",
    "                 kernel_initializer='he_normal',\n",
    "                 name='audio_embedding_layer', padding='same',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(y_a)\n",
    "\n",
    "    m = Model(inputs=x_a, outputs=y_a)\n",
    "    m.name = 'audio_model'\n",
    "\n",
    "    return m, x_a, y_a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = audio_embed_model.get_weights()[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_repr == \"mel256\":\n",
    "    audio_spec_embed_model, _, _ = construct_cnn_L3_melspec2_spec_model()\n",
    "elif input_repr == \"mel128\":\n",
    "    audio_spec_embed_model, _, _ = construct_cnn_L3_melspec1_spec_model()\n",
    "else:\n",
    "    audio_spec_embed_model, _, _ = construct_cnn_L3_kapredbinputbn_spec_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_spec_embed_model.set_weights(weights)\n",
    "audio_spec_embed_model.save(audio_output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(audio_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_spec_embed_model.save(audio_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access audio_output_path: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "ls audio_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_gzip(audio_output_path)\n",
    "compress_bz2(audio_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
